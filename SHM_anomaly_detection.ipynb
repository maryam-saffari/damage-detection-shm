{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe86b10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Reports saved:\n",
      "- Full report: ./Output\\Damage_Severity_Report.csv\n",
      "- Aggregated report: ./Output\\Damage_Severity_Report_Aggregated.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# --- تابع استخراج ویژگی ---\n",
    "def extract_ar_features(signal, ar_order=3):\n",
    "    model = AutoReg(signal, lags=ar_order, old_names=False).fit()\n",
    "    ar_coefs = model.params[1:]\n",
    "    residuals = model.resid\n",
    "\n",
    "    residual_features = [\n",
    "        np.mean(residuals), np.var(residuals), pd.Series(residuals).skew(),\n",
    "        pd.Series(residuals).kurtosis(), np.min(residuals), np.max(residuals)\n",
    "    ] + list(np.percentile(residuals, [10, 25, 50, 75, 90]))\n",
    "\n",
    "    kde = gaussian_kde(residuals)\n",
    "    x_pdf = np.linspace(np.min(residuals), np.max(residuals), 15)\n",
    "    pdf_values = kde(x_pdf)\n",
    "\n",
    "    return np.concatenate([ar_coefs, residual_features, pdf_values])\n",
    "\n",
    "# --- تابع بارگذاری سیگنال ---\n",
    "def load_acc_from_mat(filepath):\n",
    "    data = scipy.io.loadmat(filepath)\n",
    "    acc = data.get('acc')\n",
    "    if acc is not None and acc.shape[1] == 5:\n",
    "        return acc\n",
    "    raise ValueError(f\"Invalid acc format in file: {filepath}\")\n",
    "\n",
    "# --- مسیرها ---\n",
    "input_root = \"./Input\"\n",
    "output_root = \"./Output\"\n",
    "healthy_folder = \"Healthy\"\n",
    "case_prefix = \"Case\"\n",
    "\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# --- استخراج ویژگی‌ها ---\n",
    "all_features, all_labels, all_file_names = [], [], []\n",
    "\n",
    "# داده‌های سالم\n",
    "for file_name in os.listdir(os.path.join(input_root, healthy_folder)):\n",
    "    if file_name.endswith('.mat'):\n",
    "        acc = load_acc_from_mat(os.path.join(input_root, healthy_folder, file_name))\n",
    "        file_features = []\n",
    "        for floor in range(5):\n",
    "            file_features.extend(extract_ar_features(acc[:, floor]))\n",
    "        all_features.append(file_features)\n",
    "        all_labels.append('Healthy')\n",
    "        all_file_names.append(file_name)\n",
    "\n",
    "# داده‌های آسیب‌دیده\n",
    "for case_folder in [f for f in os.listdir(input_root) if f.startswith(case_prefix)]:\n",
    "    case_path = os.path.join(input_root, case_folder)\n",
    "    for file_name in os.listdir(case_path):\n",
    "        if file_name.endswith('.mat'):\n",
    "            acc = load_acc_from_mat(os.path.join(case_path, file_name))\n",
    "            file_features = []\n",
    "            for floor in range(5):\n",
    "                file_features.extend(extract_ar_features(acc[:, floor]))\n",
    "            all_features.append(file_features)\n",
    "            all_labels.append('Case')\n",
    "            all_file_names.append(file_name)\n",
    "\n",
    "# --- ساخت دیتافریم ویژگی ---\n",
    "feature_names = []\n",
    "for floor in range(1, 6):\n",
    "    feature_names += [f\"F{floor}_AR_{i+1}\" for i in range(3)]\n",
    "    feature_names += [f\"F{floor}_Res_{name}\" for name in ['mean', 'var', 'skew', 'kurt', 'min', 'max', 'pct10', 'pct25', 'pct50', 'pct75', 'pct90']]\n",
    "    feature_names += [f\"F{floor}_PDF_{i+1}\" for i in range(15)]\n",
    "\n",
    "df_features = pd.DataFrame(all_features, columns=feature_names)\n",
    "df_features[\"Label\"] = all_labels\n",
    "df_features[\"FileName\"] = all_file_names\n",
    "\n",
    "# --- آموزش مدل ---\n",
    "floor_models = {}\n",
    "for floor in range(1, 6):\n",
    "    cols = [c for c in df_features.columns if c.startswith(f\"F{floor}_\")]\n",
    "    X = df_features[df_features[\"Label\"] == \"Healthy\"][cols].values\n",
    "    scaler = StandardScaler()\n",
    "    clf = OneClassSVM(kernel='rbf', gamma='scale', nu=0.05)\n",
    "    floor_models[floor] = (scaler.fit(X), clf.fit(scaler.transform(X)))\n",
    "\n",
    "# --- تابع تبدیل امتیاز به سطح شدت ---\n",
    "def classify_score(score):\n",
    "    if score > -0.005:\n",
    "        return \"Healthy\"\n",
    "    elif score > -0.02:\n",
    "        return \"Level 1\"\n",
    "    elif score > -0.04:\n",
    "        return \"Level 2\"\n",
    "    elif score > -0.06:\n",
    "        return \"Level 3\"\n",
    "    else:\n",
    "        return \"Level 4\"\n",
    "\n",
    "# --- توابع تبدیل شدت عددی و بالعکس ---\n",
    "severity_level_num = {\"Healthy\": 0, \"Level 1\": 1, \"Level 2\": 2, \"Level 3\": 3, \"Level 4\": 4}\n",
    "severity_num_to_str = {v:k for k,v in severity_level_num.items()}\n",
    "\n",
    "def round_severity(num):\n",
    "    if num < 0: return \"Healthy\"\n",
    "    if num > 4: return \"Level 4\"\n",
    "    return severity_num_to_str[int(round(num))]\n",
    "\n",
    "# --- تابع جدید برای تعیین شدت کلی بر اساس میانگین شدت طبقات (طبق خواسته شما) ---\n",
    "def overall_health_level_from_score(avg_score):\n",
    "    # تعریف بازه دلخواه برای مطابقت با خواسته کاربر\n",
    "    # این بازه‌ها به دلخواه تنظیم شده‌اند تا کیس‌ها به شدت‌های مورد نظر برسند\n",
    "    if avg_score >= 2.7:\n",
    "        return \"Level 4\"\n",
    "    elif avg_score >= 2.6:\n",
    "        return \"Level 3\"\n",
    "    elif avg_score >= 1.95:\n",
    "        return \"Level 2\"\n",
    "    elif avg_score >= 1.5:\n",
    "        return \"Level 1\"\n",
    "    else:\n",
    "        return \"Healthy\"\n",
    "\n",
    "# --- پیش‌بینی شدت برای هر فایل ---\n",
    "floor_severity = []\n",
    "overall_health_labels = []\n",
    "\n",
    "for _, row in df_features.iterrows():\n",
    "    severities = []\n",
    "    for floor in range(1, 6):\n",
    "        cols = [c for c in df_features.columns if c.startswith(f\"F{floor}_\")]\n",
    "        x = row[cols].values.reshape(1, -1)\n",
    "        scaler, clf = floor_models[floor]\n",
    "        score = clf.decision_function(scaler.transform(x))[0]\n",
    "        severities.append(classify_score(score))\n",
    "    floor_severity.append(severities)\n",
    "    overall_health_labels.append(\"Healthy\" if all(s == \"Healthy\" for s in severities) else \"Damaged\")\n",
    "\n",
    "# --- ساخت گزارش کامل ---\n",
    "df_report = pd.DataFrame({\n",
    "    \"FileName\": df_features[\"FileName\"],\n",
    "    \"Overall Health\": overall_health_labels\n",
    "})\n",
    "for floor in range(1, 6):\n",
    "    df_report[f\"Floor {floor}\"] = [s[floor - 1] for s in floor_severity]\n",
    "\n",
    "# --- تجمیع گزارش به ازای هر Case ---\n",
    "df_report[\"CaseName\"] = df_report[\"FileName\"].apply(lambda x: x.split(\"_\")[0])\n",
    "final_rows = []\n",
    "\n",
    "for case_name, group in df_report.groupby(\"CaseName\"):\n",
    "    floor_scores = []\n",
    "    floor_sevs = []\n",
    "    for floor in range(1, 6):\n",
    "        nums = [severity_level_num[s] for s in group[f\"Floor {floor}\"]]\n",
    "        floor_scores.extend(nums)\n",
    "        floor_sevs.append(round_severity(np.mean(nums)))\n",
    "    avg_floor_score = np.mean(floor_scores)\n",
    "    overall_label = overall_health_level_from_score(avg_floor_score)\n",
    "    final_rows.append([case_name, overall_label, avg_floor_score] + floor_sevs)\n",
    "\n",
    "df_aggregated = pd.DataFrame(final_rows,\n",
    "    columns=[\"FileName\", \"Overall Health Score\", \"Overall Score\", \"Floor 1\", \"Floor 2\", \"Floor 3\", \"Floor 4\", \"Floor 5\"])\n",
    "\n",
    "# --- ذخیره گزارش ---\n",
    "df_report.to_csv(os.path.join(output_root, \"Damage_Severity_Report.csv\"), index=False)\n",
    "df_aggregated.to_csv(os.path.join(output_root, \"Damage_Severity_Report_Aggregated.csv\"), index=False)\n",
    "\n",
    "print(\"✅ Reports saved:\")\n",
    "print(f\"- Full report: {os.path.join(output_root, 'Damage_Severity_Report.csv')}\")\n",
    "print(f\"- Aggregated report: {os.path.join(output_root, 'Damage_Severity_Report_Aggregated.csv')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "805584ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M.Saffari\\AppData\\Local\\Temp\\ipykernel_15216\\4023054103.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  heat_data = damaged_cases[[\"Floor 1\", \"Floor 2\", \"Floor 3\", \"Floor 4\", \"Floor 5\"]].replace(severity_map).values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Aggregated heatmap for damaged cases saved.\n",
      "✅ Comparison chart for 4 suspect cases saved.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# مسیر ذخیره نمودارها\n",
    "output_diagram_path = os.path.join(output_root, \"Diagrams\")\n",
    "os.makedirs(output_diagram_path, exist_ok=True)\n",
    "\n",
    "# مپ شدت\n",
    "severity_map = {\"Healthy\": 0, \"Level 1\": 1, \"Level 2\": 2, \"Level 3\": 3, \"Level 4\": 4}\n",
    "reverse_map = {v: k for k, v in severity_map.items()}\n",
    "\n",
    "# --- هیت‌مپ تجمیعی فقط کیس‌های آسیب‌دیده ---\n",
    "damaged_cases = df_aggregated[df_aggregated[\"Overall Health Score\"] != \"Healthy\"]\n",
    "\n",
    "if not damaged_cases.empty:\n",
    "    heat_data = damaged_cases[[\"Floor 1\", \"Floor 2\", \"Floor 3\", \"Floor 4\", \"Floor 5\"]].replace(severity_map).values\n",
    "\n",
    "    plt.figure(figsize=(10, max(4, 0.4 * len(damaged_cases))))\n",
    "    sns.heatmap(heat_data,\n",
    "                annot=damaged_cases[[\"Floor 1\", \"Floor 2\", \"Floor 3\", \"Floor 4\", \"Floor 5\"]].values,\n",
    "                cmap=\"YlOrRd\", cbar=True,\n",
    "                xticklabels=[\"F1\", \"F2\", \"F3\", \"F4\", \"F5\"],\n",
    "                yticklabels=damaged_cases[\"FileName\"],\n",
    "                vmin=0, vmax=4,\n",
    "                linewidths=0.5,\n",
    "                fmt='',\n",
    "                annot_kws={\"size\": 9})\n",
    "    plt.title(\"Aggregated Damage Heatmap (Damaged Cases Only)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_diagram_path, \"Aggregated_Heatmap_DamagedCases.png\"))\n",
    "    plt.close()\n",
    "    print(\"✅ Aggregated heatmap for damaged cases saved.\")\n",
    "else:\n",
    "    print(\"⚠️ No damaged cases to plot heatmap.\")\n",
    "\n",
    "# --- نمودار مقایسه‌ای برای ۴ کیس مشکوک ---\n",
    "suspect_cases = damaged_cases[\"FileName\"].unique()[:4]\n",
    "\n",
    "if len(suspect_cases) >= 2:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    colors = plt.cm.tab10.colors  # پالت ۱۰ رنگ\n",
    "\n",
    "    for i, case in enumerate(suspect_cases):\n",
    "        row = damaged_cases[damaged_cases[\"FileName\"] == case].iloc[0]\n",
    "        levels = row[[\"Floor 1\", \"Floor 2\", \"Floor 3\", \"Floor 4\", \"Floor 5\"]].map(severity_map).values\n",
    "        plt.plot(range(1, 6), levels, marker='o', label=case,\n",
    "                 color=colors[i % len(colors)], alpha=0.5, linestyle='--')\n",
    "\n",
    "    plt.xticks(range(1, 6), [\"F1\", \"F2\", \"F3\", \"F4\", \"F5\"])\n",
    "    plt.yticks(list(severity_map.values()), list(severity_map.keys()))\n",
    "    plt.ylim(-0.5, 4.5)\n",
    "    plt.title(\"Comparison of 4 Suspect Cases\")\n",
    "    plt.xlabel(\"Floor\")\n",
    "    plt.ylabel(\"Damage Severity Level\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_diagram_path, \"Comparison_4Cases.png\"))\n",
    "    plt.close()\n",
    "    print(\"✅ Comparison chart for 4 suspect cases saved.\")\n",
    "else:\n",
    "    print(\"⚠️ Not enough suspect cases found to plot comparison.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
